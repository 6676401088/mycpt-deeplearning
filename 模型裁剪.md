主要包含两方面工作

1. 模型加速
2. 模型裁剪

---

其实模型裁剪也会对模型有加速效果

## 模型加速
有个比较常见的算法是将w这个matrix进行矩阵分解，将其变成两个向量乘的样子。

缺点

1. 加速有限
2. 不能fine tuning

如果不贪心的话，几倍的加速还是有的。相对于cpu哈，gpu的话，效果不是很明显

---


## 模型裁剪

据说谷歌的模型就是通过裁剪之后，放入手机中。

这个是有生理学，或者说是生物学依据的。就是大脑的神经元连接虽然多，但是不是全部激活，它是局部激活的。
只有10%以下的神经元是激活的。

那么方法是什么呢，从模型的角度就是用统计的方法，找到那些不活跃的连接，如果从计算一点的角度，就是将那些w中的元素置为零，这样其实是将一个稠密矩阵，转为了一个稀疏矩阵。计算量自然是少了很多，80%～90%的参数都可以置为0. 我得查一下，稀疏矩阵和稠密矩阵的计算复杂度，看看在计算复杂度上是否有明显的优势。

有点想PCA的方法，但感觉是结果一样，但是过程不同。

减少连接，就会减少信息量，那么自然，最后的结果就会差一点，那么没有关系，我们可以fine tune，在新的网络拓扑上做细小的修补。

这里有几个信息可以考虑

1. 稠密矩阵->稀疏矩阵
2. 稀疏矩阵的bp咋做？

---

方法

1. 


---

基本数据

1. 人类大脑中的神经元大概有860亿，其中的大脑皮层的数量为140亿，这个统计方法。
2. 人脑的每个神经元的平均有1k个连接
3. 人脑的神经元的连接是动态的，不是静态的，15岁是个分水岭。在此之前是增长，之后是衰减。
