为了避免文件名字太长，所以切断了。

问题是，神经网络为什么需要非线性激活函数，为什么relu 能够避免梯度消失。

---

## 第一个问题，为什么要引入激活函数
注意这里有定语，**非线性**

## 为什么使用relu
