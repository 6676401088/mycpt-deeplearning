背景介绍

现在用rmsprop 训练22k的imgenet模型，结果超出预料

1. 竟然收敛了
2. 竟然收敛的还不错
3. 不用设置learn rate了
4. 不用设置动量了

简单的评价是，傻瓜还好用

---

### 第一次用rmsprop

这次是用不是我用的，是组里的XLL同学在尝试，当时要解决的一个问题是，什么样的方法可以最快速的收敛imagenet（1K）， 基于caffe 平台，尝试了

1. adam
2. adagrad
3. adadelta
4. rmsprop

效果不好

现在想想，当时的情况很复杂，无法全部将问题算到rmsprop的头上

----

### 第二次用rmsprop

这次的主人公就是我了，我用sgd 训练了一个22k的模型，效果还行吧，但是感觉还是不够高，决定做一下fine tune

训练好的数据的精度是32%，结果一用上rmsprop,精度瞬间降到了0.002%，
当时我真的吓坏了，当时只有一个想法，难道这个rmsprop算法比快排还难写，那个平台都实现不了？

---

### 如何验证rmsprop

1. 用minist
2. 用cifir10


小的模型，小的数据集，速度快啊，可以很快的得到结果，而且单机就可以解决问题的。不用上大规模的集群

我的实验结果，rmsprop是work的

可以把rmsprop有问题的概率降低了很多。

那么会不会因为，rmsprop算的 梯度，一下子从小的地方跳出来了，毕竟这两个算法对待梯度的方法不一样。

那么怎么验证这个问题，那就是从头训练 ，看能不能收敛

结果我可以告诉大家，收敛了！！！
收敛了！

---

总结一下

rmsprop的优势

减少了超参数的数量

1. lr
2. 动量


速度还不错

算是一个很大的收获！
